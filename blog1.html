<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <link rel="stylesheet" type="text/css" href="style.css">
        <script type="text/javascript" src="scripts/secrets.js"></script>
        <link rel="icon" href="purple.png">

        <link href="https://fonts.googleapis.com/css2?family=Work+Sans&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Work+Sans:wght@600&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@500&display=swap" rel="stylesheet">
        
    </head>

    <body>

    <div class = "container">
        <div class = "intro">
            <title>Sophie Groenwold</title>

            <h1 id = "colorchange" onclick = "changeColor">
                <a class = "nounderline" href = "http://sophiegroenwold.com">Sophie Groenwold</a>

                <!-- BEGIN LINKS  -->
                
                <div class = "container2">

                    <div class = "linksContainer1">
                        <div id = "crossFade">
                            <img class = "top" alt = "Github" src="images/githubHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;">
                            <a class = "bottom" href="https://github.com/sophiegroenwold" target = "_blank">
                                <img border="0" alt="GitHub" src="images/githubHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;"></a>
                        </div>
                    </div>
        
                    <div class = "linksContainer2">
                        <div id = "crossFade">
                            <img class="top" alt="Twitter" src="images/twitterHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;">
                            <a class = "bottom" href="https://twitter.com/sophiegroenwold" target = "_blank">
                                <img border="0" alt="Facebook" src="images/twitterHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;"></a>
                        </div>
                    </div>
                
                    <div class = "linksContainer3">
                        <div id = "crossFade">
                            <img class = "top" alt="Linkedin" src="images/linkedinHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;">
                            <a class = "bottom" href="https://www.linkedin.com/in/sophiegroenwold/" target = "_blank">
                                <img border="0" alt="Linkedin" src="images/linkedinHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;"></a>
                        </div>
                    </div>
        
                    <div class = "linksContainer4">
                        <div id = "crossFade">
                            <img class = "top" alt="Email" src="images/gmailHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;">
                            <a class = "bottom" href="mailto:sophiegroenwold@ucsb.edu" target = "_blank">
                                <img border="0" alt="Email" src="images/gmailHover.png" 
                                style = "width:20px; height: 20px; margin: 15px;"></a><br>
                        </div>
                    </div>
                            
                </div>

                <hr class = "new" noshade>

            </h1>

            <!-- BEGIN WRITING -->
            <h2>Children Should Not be the Target of Individualized Algorithms</h2>

            <p class = "block">
                <i>1.29.20</i>
            </p>

            <p class = "block">
                Social media algorithms are a popular topic of scrutiny as of late. While their precise details are hidden in the statistical mechanisms brought by machine learning and their data collection methods are buried in long Terms of Service agreements, the public is increasingly aware that their virtual worlds are carefully-curated feeds that above all else seek to maximize engagement <a class = link target = "_blank" href = "https://georgetownlawtechreview.org/social-media-algorithms-why-you-see-what-you-see/GLTR-12-2017/">(1)</a>. Some frequently discussed repercussions of these "filter bubbles" <a class = link target = "_blank" href ="https://en.wikipedia.org/wiki/Filter_bubble">(2)</a> are political polarization <a class = link target = "_blank" href = "https://greatergood.berkeley.edu/article/item/is_social_media_driving_political_polarization">(3)</a> and the amplification of societal biases <a class = link target = "_blank" href = "https://searchenterpriseai.techtarget.com/definition/machine-learning-bias-algorithm-bias-or-AI-bias">(4)</a>; however, these discussions rarely focus on the implications that social media algorithms may have on children. 
            </p>
            <p class = "block">
                “Something is Wrong on the Internet” is an essay that details the side of YouTube that uses popular characters and tropes from children’s media to produce deeply disturbing content <a class = link target = "_blank" href = "https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2">(5)</a>. Buzzwords like "finger family,” “bad baby,” and “learn colors” are crammed into video titles to draw views to content that is both automatically generated and acted out by humans. Children will start on real Peppa Pig videos and, through the recommendations of a personalized algorithm, end up on videos that feature Peppa Pig drinking bleach. Instances like these persist even on YouTube Kids, a platform that supposedly filters kid-friendly matter from normal YouTube and has increased instances of manual review <a class = link target = "_blank" href = "https://nytimes.com/2017/11/04/business/media/youtube-kids-paw-patrol.html">(6)</a>. 
            </p>
            <p class = "block">
                The question of who bears the brunt of the responsibility for preventing children’s access to such content is a difficult one. The most direct answer is YouTube, as it controls the platform and thus the means of distribution. But despite the manpower behind YouTube (which is considerable, as its parent company is Google), having a human review of every video in its entirety is unrealistic, as there are millions of instances of the upsetting content detailed above <a class = link target = "_blank" href = "https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2">(5)</a>. Algorithmic processes are the next solution, but as YouTube Kids already utilizes an automated filtering process, the success of this approach is doubtful – and after all, it seems futile to mend the damage of one algorithm with another. And this is assuming that YouTube wants to invest their effort in removing such content in the first place; under Section 230, YouTube can moderate as they see fit <a class = link target = "_blank" href = "https://en.wikipedia.org/wiki/Section_230">(7)</a>, and YouTube CEO Susan Wojcicki has indicated that they will follow the law’s example in deciding what to remove from their platform <a class = link target = "_blank" href = "https://cbsnews.com/news/youtube-susan-wojcicki-section-230-60-minutes">(8)</a>.
            </p>
            <p class = "block">
                Without the means or motivation for YouTube to restrict inappropriate content on their platform, the immediate responsibility is passed to a child’s parents. This seems to be the track taken both by YouTube themselves and by current child protection policy. In terms of the former, YouTube Kids requires that their users create an account with the help of a parent or guardian and allows parents to have complete control over what their children view. This places the burden of research on parents. Similar to how the opt-in versus opt-out debate assumes that most users will not regularly check their privacy settings, it is far-fetched to take for granted that all parents will carefully monitor the content that their children have access to. Indeed, the premise of YouTube Kids as a platform for kids may instill a false sense of security in parents. It is also important to note that as a free service that allows parents a period of respite from actively monitoring their children, YouTube is more likely to be used as an entertainment medium for kids in lower socioeconomic classes <a class = link target = "_blank" href = "https://theoutline.com/post/2461/the-screen-time-debate-rebooted-for-youtube">(9)</a>.
            </p>
            <p class = "block">
                The Children’s Online Privacy Protection Act, or COPPA, reinforces this notion of parents as the ultimate source of protection for their children <a class = link target = "_blank" href = "https://en.wikipedia.org/wiki/Children%27s_Online_Privacy_Protection_Act">(10)</a>. COPPA requires that access to a parent or guardian’s permission is obtained before allowing children under the age of 13 to access certain types of content or before collecting any of their identifying information. By having many internet platforms seek parental consent, COPPA also essentially places the burden upon parents. Interestingly, YouTube has recently been the recipient of COPPA fines: in September 2019, the FTC held that YouTube violated COPPA by collecting information that could identify viewers of child-directed channels without parental consent <a class = link target = "_blank" href = "https://ftc.gov/news-events/blogs/business-blog/2019/11/youtube-channel-owners-your-content-directed-children">(11)</a>. In addition to paying a fine, YouTube announced that they would direct channel owners to label their content as child-oriented and use machine learning algorithms to verify labels. 
            </p>
            <p class = "block">
                While this is undoubtedly a step in the right direction, it is not enough. Checking a Terms of Service box does not mean that a parent fully understands to what extent their children’s data is collected. A machine learning algorithm built to label videos for children based on visual cues will have trouble learning the difference between a genuine Paw Patrol video and one that features Paw Patrol characters dying by way of a flaming car accident <a class = link target = "_blank" href = "https://nytimes.com/2017/11/04/business/media/youtube-kids-paw-patrol.html">(6)</a>. As is required by COPPA, YouTube provides parents with a clear Privacy Notice <a class = link target = "_blank" href = "https://kids.youtube.com/t/privacynotice">(12)</a>. This notice informs parents that personally identifiable information will not be collected (such as name, address, or contact information), but that they “collect information based on [their] child's use of the app,” including but not limited to device type and settings, IP address, and unique identifiers used to track users’ activity over time.
            </p>
            <p class = "block">
                As long as YouTube can collect persistent and unique identifiers on kids, allowing them to build personal models of child users over time, they will use this data for recommendation algorithms that expose those users to content meant to exploit and traumatize them. This is permissible under COPPA, as long as YouTube obtains parental consent of children under 13, detail what data they collect in unambiguous language, and follow data retention and deletion requirements. The latter point is essentially null, as data retention is legitimate as long as that data is still being used for the purpose it was originally collected for. Recommendation algorithms continuously build user profiles to increase their effectiveness, so any data collected for this purpose can be retained indefinitely.
            </p>
            <p class = "block">
                Thus, as it is logistically unfeasible for either YouTube or individual parents to bear full responsibility for removing, moderating, or protecting children from harmful content on the video-sharing platform, policy changes must be enacted. COPPA should be amended to prohibit the collection of long-term unique identifiers, particularly for training recommendation algorithms, when a platform can reasonably assume that a user is a child. This change would fundamentally shift power over content from the platform to the user, and prevent creators of content as described above from exploiting children by playing recommendations to their advantage. Besides the effects of protecting children unsettling media, not allowing kids to enter filter bubbles would defend them from the harms these bubbles create, many of which we likely do not yet know of. 
            </p>
            <p class = "block">
                At the end of the day, this wide-sweeping suggestion is unlikely to be enacted. It undermines the fundamental goal of social media – to keep users engaged – and would be met with strong opposition from YouTube and other relevant platforms if proposed. But the Internet can be a scary place for a child, and the law needs to adapt to the ever-changing virtual landscape that the children of today will unavoidably find themselves a part of.
            </p>

        </div>
    </div>

    </body>
</html>